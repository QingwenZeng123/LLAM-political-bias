{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Modify the prompts to include the context of the prompt\n",
    "data = pd.read_csv(\"data/prompts.csv\")\n",
    "\n",
    "article_only_context = \"You are going to be the reader of a political article. Your job is to determine whether the article is biased based on reader point of view. You answer either is-biased or is-not-biased, with no explanation. An article is-biased in its presentation of the topic, meaning that it ever exaggerates, misrepresents, omits, or otherwise distorts facts (including by making subjective opinions look like facts) for the purpose of appealing to a certain political group.\\n\"\n",
    "\n",
    "political_side_context = \"You are going to be the reader of a political article. Your job is to determine whether the article is biased based on the Reader identifies politics group.You answer either is-biased or is-not-biased, with no explanation. An article is-biased in its presentation of the topic, meaning that it ever exaggerates, misrepresents, omits, or otherwise distorts facts (including by making subjective opinions look like facts) for the purpose of appealing to a certain political group.\\n\"\n",
    "\n",
    "\n",
    "article_source_context = \"You are going to be the reader of a political article. Your job is to determine whether the article is biased. And take source of the article into consideration to provide answer. You answer either is-biased or is-not-biased, with no explanation. An article is-biased in its presentation of the topic, meaning that it ever exaggerates, misrepresents, omits, or otherwise distorts facts (including by making subjective opinions look like facts) for the purpose of appealing to a certain political group.\\n\"\n",
    "\n",
    "\n",
    "all_information_context = \"You are going to be the reader of a political article. Your job is to determine whether the article is biased. And take all the anticipants information into consideration to provide answer, which include Reader Demographics information, Readers' politics group and article source. You answer either is-biased or is-not-biased, with no explanation. An article is-biased in its presentation of the topic, meaning that it ever exaggerates, misrepresents, omits, or otherwise distorts facts (including by making subjective opinions look like facts) for the purpose of appealing to a certain political group.\\n\"\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    data.at[index, \"prompt_article_info\"] = article_only_context + row[\"prompt_article_info\"]\n",
    "    data.at[index, \"prompt_politics_info\"] = political_side_context + row[\"prompt_politics_info\"]\n",
    "    data.at[index, \"prompt_letter_source_info\"] = article_source_context + row[\"prompt_letter_source_info\"]\n",
    "    data.at[index, \"prompt_all_info\"] = all_information_context + row[\"prompt_all_info\"]\n",
    "\n",
    "data.to_csv(\"data/prompts_v2.csv\", index=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation sets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data/prompts_v2.csv')\n",
    "original_data = pd.read_csv('data/data_articles_info.csv', usecols=['id', 'bias-question', 'politics', 'article_id'])\n",
    "data['bias-question'] = original_data['bias-question']\n",
    "train, val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Write the training and validation data to csv files\n",
    "train.to_csv('data/prompts_v2_train.csv', index=False)\n",
    "val.to_csv('data/prompts_v2_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing chatGPT training prompts to a file (change the name of the column to the experiment that you want to run)\n",
    "\n",
    "COLUMN_NAME = \"prompt_article_info\"\n",
    "FILE_NAME = \"article_info_prompts.jsonl\"\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/prompts_v2_train.csv\")\n",
    "\n",
    "prompts = data[COLUMN_NAME].to_list()\n",
    "completion = data[\"bias-question\"].to_list()\n",
    "\n",
    "# {\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "chatgpt_prompts = []\n",
    "for i in range(len(prompts)):\n",
    "    chatgpt_prompts.append({\"prompt\": prompts[i], \"completion\": completion[i]})\n",
    "# Writing chatGPT training prompts to a file in jsonl format\n",
    "\n",
    "import json\n",
    "\n",
    "# {\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "with open('data/gpt_prompts/' + FILE_NAME, 'w') as f:\n",
    "    for item in chatgpt_prompts:\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
